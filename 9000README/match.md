バッチ処理の実装の際にパフォーマンスの観点で気をつけたこと【AWS Batch】

tttttttttttt




## 👀 概要

この記事は、AWS Batchを活用したバッチ処理を実装した際の記録です。


### 📌 目的

### 📖 関連ページ


### 👦 対象読者

- AWS Batchを利用したバッチ処理に興味のある方
- AWS Bedrockを利用した推薦理由のコメント化に興味のある方

### 🔗 参考リンク



## 課題

### 機能的側面

- テーブルの取り込み処理
- 機械学習処理
- 推薦理由の生成


### 非機能的側面

- 時間
    - バッチは業務時間外に実行。前日に連携されたデータを全て機械学習処理を行う。
    - 朝6時にCSV形式のデータが転送されてくるので、朝8時までの処理を行う。
- データ
    - 送られてくるデータは 1テーブルにつき1CSV。ファイル数は64個なのでテーブル数も64個。
    - S3ファイルの特定のディレクトリが洗い替えされる。(差分ではなく洗い替え。)
    - 一つでもテーブルの取り込み処理に失敗した場合、すべてのテーブルが前日の状態まで戻す。
- 処理
    - 機械学習処理はGPUの利用が必須。


## 実装

### 主要技術

- 言語 : Python3
- コンピューティング環境 : AWS Batch (Fargate/EC2 双方利用)
- データベース : Amazon Aurora Serverless PostgreSQL
- 機械学習モデル : LightGBM
- LLM : AWS Bedrock


### データ処理




#### フェーズ1 : CSVファイルのクリーニング処理

受け取ったCSVファイルはOracleから出力されたものでしたが、取り込み先のデータベースはPostgreSQLでした。
テーブルへの入力値が異なりcsvのクリーニング処理が必須となりますが、pythonでの実装した際の処理速度は不十分でした。

そこで、pythonでの置換処理をやめ、 `sed`コマンドでの置換処理に変更し、処理速度の改善を行いました。


#### フェーズ2 : 一時テーブルへのDUMP : 並列処理の実装

- AWS S3の拡張機能を使って、テーブルの取り込み処理を行う。

```sql
SELECT aws_s3.table_import_from_s3(
    'テーブル名',
    'カラムリスト', #空文字の場合、テーブルのカラムと一致
    'PostgreSQL', #COPYの引数・フォーマット
    'S3バケット名',
    'S3キー',
    'S3リージョン'
);
```




#### フェーズ3 : 本テーブルへのコピー : INDEXのつけ直し

フェーズ3では 一時テーブルに格納されたテーブルを、本テーブルに移動させる処理を行います。

> **気をつけたこと:同一トランザクションで実装**
> 
> このフェーズでは同一のトランザクションでテーブルコピーを行うため、万が一エラーが発生した際にはロールバックされます。
> そのため、「テーブルAは最新だが、テーブルBは古い」という事態は発生しません。
> 
> ごく当たり前の内容かもしれませんが、整合性を保つためには重要なことでした。

このフェーズのパフォーマンスで工夫したことは、 このフェーズでのテーブルのコピーの前にはINDEXを一度削除した ということでした。

本作業に取り組むきっかけは、INDEX が設定されたテーブルをコピーした際に想定以上の時間を要したことに違和感を覚えたためです。
ここの違和感には数値的根拠があるわけではなく、「なんとなく思っていたより速度が出ないな」と思った程度でした。

(今思えばクエリの実行計画を確認すれば良かったのですが、当時はそれを発想する時間的/精神的余力がなかったです。)

**この違和感を覚えた後、「試しにCOPY前にINDEXを削除してみよう」とトライアル的に実験したところCOPY速度が向上したのです。**
この実験で驚いたのは、**INDEXの削除/再作成時間を足しても、 INDEXがないテーブルへのCOPY時間の方が少なく済んだのです。**

`INDEXが貼られたままのテーブルへのCOPY < (INDEXの削除 + INDEXがないテーブルへのCOPY + INDEXの再作成)の速度`


### フェーズ4 : 




## 補足

Bedrockのトークン制限について
















